{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carga de la imagen:\n",
    "\n",
    "img = cv.imread('C:/Users/Gabo/Pictures/Roblox/ola.png', 1) carga una imagen desde la ruta especificada ('C:/Users/Gabo/Pictures/Roblox/ola.png') en formato de color (1 significa cargar la imagen en color). La imagen se almacena en la variable img.\n",
    "Poner 0 es b/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de una imagen de ceros:\n",
    "\n",
    " zeros = np.zeros(img.shape[:2], dtype='uint8') crea una imagen completamente negra (todos los píxeles con valores de cero) del mismo tamaño que la imagen original. Se utiliza para crear canales de color sólidos más adelante.\n",
    "Conversión de colores:\n",
    "\n",
    "img2 = cv.cvtColor(img, cv.COLOR_BGR2RGB) convierte la imagen cargada (img) de BGR (Azul, Verde, Rojo) a RGB (Rojo, Verde, Azul). Esto cambia el orden de los canales de color.\n",
    "División de canales de color:\n",
    "\n",
    "(b, g, r) = cv.split(img) divide la imagen en sus tres canales de color: azul (b), verde (g) y rojo (r).\n",
    "Mostrar canales de color por separado:\n",
    "\n",
    "cv.imshow('b', b), cv.imshow('g', g), cv.imshow('r', r) muestran cada uno de los canales de color (azul, verde y rojo) en ventanas separadas. Esto te permite visualizar cada canal por separado.\n",
    "Creación de imágenes con canales individuales:\n",
    "\n",
    "cv.imshow('b1', cv.merge([b, zeros, zeros])), cv.imshow('g1', cv.merge([zeros, g, zeros])), cv.imshow('r1', cv.merge([zeros, zeros, r])) crean y muestran imágenes individuales para cada canal de color. Cada canal se combina con imágenes de ceros para obtener un canal de color individual.\n",
    "Mostrar otras imágenes y canales:\n",
    "\n",
    "cv.imshow('img', img) muestra la imagen original.\n",
    "cv.imshow('img2', img2) muestra la imagen convertida a RGB.\n",
    "cv.imshow('zeros', zeros) muestra la imagen de ceros (completamente negra).\n",
    "cv.imshow('grb', cv.merge([g, r, b])) combina y muestra los canales de color en un nuevo orden (verde, rojo, azul).\n",
    "Espera de tecla y cierre de ventanas:\n",
    "\n",
    "cv.waitKey(0) espera hasta que se presione cualquier tecla y luego continúa.\n",
    "cv.destroyAllWindows() cierra todas las ventanas abiertas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#### Mascaras para destacar colores\n",
    "\n",
    "Conversión de colores:\n",
    "\n",
    "img2 = cv.cvtColor(img, cv.COLOR_BGR2RGB) convierte la imagen cargada (img) de BGR (Azul, Verde, Rojo) a RGB (Rojo, Verde, Azul). Esto cambia el orden de los canales de color.\n",
    "Conversión a espacio de color HSV:\n",
    "\n",
    "img3 = cv.cvtColor(img2, cv.COLOR_RGB2HSV) convierte la imagen RGB (img2) al espacio de color HSV, que es útil para trabajar con la información de color en términos de matiz, saturación y valor.\n",
    "Definición de umbrales de color:\n",
    "\n",
    "umbralbajo y umbralalto son tuplas que definen el rango de colores que se quiere resaltar en la imagen en el espacio de color HSV. En este caso, se selecciona el rango de colores que corresponde al rojo en la parte baja y alta del espectro de colores.\n",
    "umbralbajob y umbralaltob son tuplas que definen el rango de colores para los tonos de rojo que se encuentran en la transición entre 0 y 180 grados en el espacio de color HSV.\n",
    "Creación de máscaras:\n",
    "\n",
    "mascara1 y mascara2 se crean utilizando la función cv.inRange(), que crea una máscara binaria donde los píxeles dentro del rango especificado se establecen en 255 (blanco) y los píxeles fuera del rango se establecen en 0 (negro).\n",
    "Combinación de máscaras:\n",
    "\n",
    "mascara = mascara1 + mascara2 combina las dos máscaras binarias en una sola máscara, resaltando el rango de colores especificado.\n",
    "Aplicación de la máscara a la imagen original:\n",
    "\n",
    "resultado = cv.bitwise_and(img, img, mask=mascara) aplica la máscara mascara a la imagen original (img) utilizando la operación \"AND bitwise\", lo que resalta los colores que están dentro del rango de la máscara.\n",
    "Visualización de imágenes y máscara:\n",
    "\n",
    "cv.imshow('resultado', resultado) muestra la imagen resultante con los colores resaltados.\n",
    "cv.imshow('mascara', mascara) muestra la máscara binaria que se utilizó para resaltar los colores.\n",
    "cv.imshow('img', img) muestra la imagen original.\n",
    "cv.imshow('img2', img2) muestra la imagen convertida a RGB.\n",
    "cv.imshow('img3', img3) muestra la imagen convertida al espacio de color HSV.\n",
    "Espera de tecla y cierre de ventanas:\n",
    "\n",
    "cv.waitKey(0) espera hasta que se presione cualquier tecla y luego continúa.\n",
    "cv.destroyAllWindows() cierra todas las ventanas abiertas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "#### Captura de cam y filtros\n",
    "Inicialización de la cámara:\n",
    "\n",
    "cap = cv.VideoCapture(0) inicializa la captura de video desde la cámara. El argumento 0 indica que se utilizará la cámara predeterminada. Si la cámara no se puede abrir, el programa imprime un mensaje de error y sale.\n",
    "Bucle principal para capturar y procesar video:\n",
    "\n",
    "Se inicia un bucle while True para capturar continuamente fotogramas del video de la cámara y procesarlos en tiempo real.\n",
    "Captura de un fotograma de la cámara:\n",
    "\n",
    "ret, img = cap.read() captura un fotograma de video de la cámara y lo almacena en las variables ret (indicando si la captura fue exitosa) e img (el fotograma capturado).\n",
    "Conversión de colores:\n",
    "\n",
    "img2 = cv.cvtColor(img, cv.COLOR_BGR2RGB) convierte el fotograma capturado (img) de BGR (Azul, Verde, Rojo) a RGB (Rojo, Verde, Azul). Esto cambia el orden de los canales de color.\n",
    "Conversión a espacio de color HSV:\n",
    "\n",
    "img3 = cv.cvtColor(img2, cv.COLOR_RGB2HSV) convierte la imagen RGB (img2) al espacio de color HSV, que es útil para trabajar con la información de color en términos de matiz, saturación y valor.\n",
    "Definición de umbrales de color:\n",
    "\n",
    "umbralbajo y umbralalto son tuplas que definen el rango de colores que se quiere resaltar en el video en tiempo real en el espacio de color HSV. En este caso, se selecciona el rango de colores que corresponde al rojo en el espectro de colores.\n",
    "Creación de una máscara:\n",
    "\n",
    "mascara = cv.inRange(img3, umbralbajo, umbralalto) crea una máscara binaria donde los píxeles dentro del rango especificado se establecen en 255 (blanco) y los píxeles fuera del rango se establecen en 0 (negro).\n",
    "Aplicación de la máscara al fotograma original:\n",
    "\n",
    "resultado = cv.bitwise_and(img, img, mask=mascara) aplica la máscara mascara al fotograma original (img) utilizando la operación \"AND bitwise\", lo que resalta los colores que están dentro del rango de la máscara y muestra el resto en negro.\n",
    "Visualización del resultado:\n",
    "\n",
    "cv.imshow('resultado', resultado) muestra el resultado del filtrado con la máscara, donde solo los colores dentro del rango de umbrales son visibles en la imagen.\n",
    "Visualización del fotograma original:\n",
    "\n",
    "cv.imshow('img', img) muestra el fotograma original sin procesar.\n",
    "Salida del bucle:\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'q'. Cuando se presiona la tecla 'q', se rompe el bucle (if cv.waitKey(1) == ord('q'):).\n",
    "Liberación de recursos:\n",
    "\n",
    "Al salir del bucle, se libera la cámara (cap.release()) y se cierran las ventanas abiertas (cv.destroyAllWindows()).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "#### Codigo de reconocimiento facial.\n",
    "\n",
    "Carga del clasificador de cascada frontal:\n",
    "\n",
    "rostro = cv.CascadeClassifier('C:/Users/Gabo/Documents/JupyterNotebook/haarcascades/haarcascade_frontalface_alt.xml') carga un clasificador de cascada previamente entrenado para la detección de rostros. El archivo XML del clasificador se especifica como 'haarcascade_frontalface_alt.xml'. Puedes cambiar este archivo XML por otro si deseas detectar otros tipos de objetos, como caras de gatos, como se indica en el comentario.\n",
    "Inicialización de la cámara:\n",
    "\n",
    "cap = cv.VideoCapture(0) inicializa la captura de video desde la cámara web (índice 0). Esto abre la cámara predeterminada para capturar video en tiempo real.\n",
    "Bucle principal para el reconocimiento facial:\n",
    "\n",
    "Se inicia un bucle while True para capturar continuamente fotogramas de video de la cámara y realizar el reconocimiento facial en tiempo real.\n",
    "Captura de un fotograma de la cámara:\n",
    "\n",
    "ret, frame = cap.read() captura un fotograma de video desde la cámara y lo almacena en las variables ret (indicando si la captura fue exitosa) y frame (el fotograma capturado).\n",
    "Conversión a escala de grises:\n",
    "\n",
    "gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) convierte el fotograma capturado (frame) a escala de grises utilizando cv.cvtColor(). Esto simplifica el procesamiento de detección facial.\n",
    "Detección de rostros:\n",
    "\n",
    "rostros = rostro.detectMultiScale(gray, 1.3, 4) utiliza el clasificador de cascada Haar para detectar rostros en el fotograma en escala de grises (gray). Los parámetros 1.3 y 4 son factores de escala y vecinos mínimos utilizados para ajustar la detección de rostros.\n",
    "Dibujo de rectángulos alrededor de los rostros detectados:\n",
    "\n",
    "Para cada conjunto de coordenadas (x, y, w, h) que representan un rostro detectado en la imagen, se dibuja un rectángulo alrededor del rostro utilizando cv.rectangle(). Además, se dibujan rectángulos alrededor de los ojos, la nariz y la boca dentro del área del rostro detectado, lo que crea un efecto de resaltado de estas partes faciales.\n",
    "Visualización del resultado:\n",
    "\n",
    "cv.imshow('rostros', frame) muestra el fotograma de video con los rectángulos dibujados alrededor de los rostros y partes faciales detectadas.\n",
    "Espera de tecla y salida del bucle:\n",
    "\n",
    "k = cv.waitKey(1) espera 1 milisegundo para la entrada del usuario. Si se presiona la tecla 'Esc' (código 27), el bucle se interrumpe (break), lo que detiene la ejecución del programa.\n",
    "Liberación de recursos:\n",
    "\n",
    "Al salir del bucle, se libera la cámara (cap.release()) y se cierran todas las ventanas abiertas (cv.destroyAllWindows())."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "\n",
    "###### 1. Importación de bibliotecas:\n",
    "   ###### - Se importa la biblioteca OpenCV como `cv2` para trabajar con el procesamiento de imágenes y videos.\n",
    "\n",
    "###### 2. Carga del clasificador de cascada frontal:\n",
    "   ###### - Se carga un clasificador de cascada previamente entrenado para la detección de rostros. El archivo XML del clasificador se especifica como 'haarcascade_frontalface_alt.xml'.\n",
    "\n",
    "###### 3. Inicialización de la cámara:\n",
    "   ###### - Se inicializa la cámara web capturando el flujo de video en tiempo real. `cap = cv.VideoCapture(0)` abre la cámara web en el índice 0, que suele ser la cámara predeterminada.\n",
    "###### 4. Bucle principal:\n",
    "   ###### - Se inicia un bucle infinito (`while True`) para capturar continuamente los fotogramas de la cámara web y procesarlos.\n",
    "\n",
    "###### 5. Captura de un fotograma:\n",
    "   ###### - Se utiliza `cap.read()` para capturar un fotograma de la cámara web, y se almacena en las variables `ret` y `frame`.\n",
    "\n",
    "###### 6. Conversión a escala de grises:\n",
    "   ###### - El fotograma capturado se convierte a escala de grises utilizando `cv.cvtColor()` para facilitar la detección.\n",
    "\n",
    "###### 7. Detección de rostros:\n",
    "   ###### - Se utiliza el clasificador de cascada frontal para detectar rostros en el fotograma. `rostros = rostro_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4)` devuelve las coordenadas (x, y, ancho, alto) de los rostros detectados en la escala de grises.\n",
    "\n",
    "###### 8. Dibujo de rectángulos:\n",
    "   ###### - Para cada rostro detectado, se dibuja un rectángulo alrededor del rostro utilizando `cv.rectangle()`. Luego, se calculan las coordenadas de los rectángulos de los ojos, la boca y la nariz en función del tamaño del rostro y se dibujan rectángulos similares alrededor de estas características faciales.\n",
    "\n",
    "###### 9. Visualización del fotograma:\n",
    "   ###### - Se muestra el fotograma procesado en una ventana con el título 'rostros' utilizando `cv.imshow()`.\n",
    "\n",
    "###### 10. Espera de tecla:\n",
    "######     - Se utiliza `cv.waitKey(1)` para esperar 1 milisegundo para la entrada del usuario. Si se presiona la tecla 'Esc' (código 27), el bucle se interrumpe (`break`).\n",
    "\n",
    "###### 11. Liberación de recursos:\n",
    "  ######   - Al salir del bucle, se libera la cámara y se cierra la ventana utilizando `cap.release()` y `cv.destroyAllWindows()` respectivamente.\n",
    "\n",
    "###### En resumen, este código detecta rostros en un feed de video en tiempo real, dibuja rectángulos alrededor de los rostros, ojos, boca y nariz, y muestra el resultado en una ventana de visualización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 con cubrebocas\n",
    "500 sin     \" \"\n",
    "\n",
    "100 cada uno.\n",
    "\n",
    "C:\\Program Files\\Cascade Trainer GUI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
